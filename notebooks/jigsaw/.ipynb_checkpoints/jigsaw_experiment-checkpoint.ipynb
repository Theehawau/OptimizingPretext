{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb0764-f13b-4afd-9bd7-5fdd58b63f8f",
   "metadata": {},
   "source": [
    "# JigSaw pretext task\n",
    "Following [the original implementation](https://arxiv.org/pdf/1603.09246) <br>\n",
    "Also useful to look at [the FAIR paper](https://arxiv.org/pdf/1905.01235) (page 12), for details on the implementation.<br>\n",
    "Adapted to use ResNet18 instead of CFN.\n",
    "TODO\n",
    "- Organize into separate .py modules for JigSaw utils\n",
    "- Create runner script that can use up to 4 GPUs for faster training.\n",
    "- Add ViT\n",
    "- Change training dataset to something w/ resolution of ~255x255 to avoid the need to upscate data\n",
    "- Add the evaluations -> basically take the (pretrained) resnet module and plug it into another module w/ a clean classification head \n",
    "    - linear probing\n",
    "    - full ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150c7425-5ca5-41b9-b507-1e58b5eef889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f13f6ce-5c49-4582-a48f-5cf9007a7518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x150d94bcedb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility -> maybe use pytorch lightning for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b2f0d-4b60-42b4-ab97-310fa9992e09",
   "metadata": {},
   "source": [
    "## Load Tiny-ImageNet from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f139d43-ccdb-4e7e-b145-55e7a2aaf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinyImageNet_dataset = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "# We can also download it from here http://cs231n.stanford.edu/tiny-imagenet-200.zip but i think HFs its easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f3f690-4089-4f6b-876f-7efa5644439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinyImageNet_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed96c94-df0f-429f-9f66-139dd1e24f72",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f475fa7d-6a08-4ece-9063-5a78f5cf4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(n_permutations, n_tiles):\n",
    "    \"\"\"\n",
    "    Generates a list of permutations, these will essentially be the 'gold truth' labels\n",
    "    \"\"\"\n",
    "    permutations = []\n",
    "    seen = set()\n",
    "    while len(permutations) < n_permutations:\n",
    "        perm = tuple(np.random.permutation(n_tiles))\n",
    "        if perm not in seen:\n",
    "            permutations.append(perm)\n",
    "            seen.add(perm)\n",
    "    return permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d220da-4f5d-49fa-8032-73a5a69bdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n_permutations permutations for 9 tiles, these values are related to the complexity of the task and should be updated as necessary\n",
    "n_permutations = 1000 ##essentially the number of classes\n",
    "n_tiles = 9\n",
    "permutations = generate_permutations(n_permutations, n_tiles)\n",
    "\n",
    "# Enumerate and store permutations\n",
    "permutations_dict = {i: perm for i, perm in enumerate(permutations)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc9dcc6-d17b-49a3-98e0-1337e398ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These indices will basically be the possible \"gold\" labels :p\n"
     ]
    }
   ],
   "source": [
    "permutations[:3] \n",
    "print('These indices will basically be the possible \"gold\" labels :p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46e30a4-b111-4a11-a2a8-b3eaeb7cf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawPuzzleDataset(data.Dataset):\n",
    "    def __init__(self, hf_dataset, permutations, transform=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            hf_dataset: HuggingFace Dataset object.\n",
    "            permutations: List of permutations.\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.dataset = hf_dataset\n",
    "        self.permutations = permutations\n",
    "        self.n_permutations = len(permutations)\n",
    "        self.n_tiles = 9  # 3x3 grid -> this can be modified later\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image from the HuggingFace dataset and convert to RGB\n",
    "        image = self.dataset[idx]['image'].convert('RGB')  # Ensure image is in RGB\n",
    "\n",
    "        # We'll resize it to 255x255 since this is ResNet's input size\n",
    "        image = image.resize((255, 255))\n",
    "\n",
    "        # Divide the image into 3x3 grid of tiles (85x85 pixels each)\n",
    "        tiles = []\n",
    "        tile_size = 85 # 85 * 3 = 255\n",
    "\n",
    "        ## Iterate over possible tiles and create the patches\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "\n",
    "                '''\n",
    "                Original paper explanation: We randomly crop a 225 × 225 pixel window from an image (red dashed box), divide it into a 3 × 3 grid, and randomly pick a 64 × 64 pixel tiles from each 75 × 75 pixel cell.\n",
    "                '''\n",
    "\n",
    "                # Get boundaries and crop\n",
    "                left = j * tile_size\n",
    "                upper = i * tile_size\n",
    "                right = left + tile_size\n",
    "                lower = upper + tile_size\n",
    "                tile = image.crop((left, upper, right, lower))\n",
    "                \n",
    "                # Random crop of 64x64 pixels with random shifts\n",
    "                shift_max = tile_size - 64  # Max shift to introduce randomness\n",
    "                left_shift = random.randint(0, shift_max)\n",
    "                upper_shift = random.randint(0, shift_max)\n",
    "                tile = tile.crop((left_shift, upper_shift, left_shift + 64, upper_shift + 64))\n",
    "                \n",
    "                # Apply any transform passed as argument\n",
    "                if self.transform is not None:\n",
    "                    tile = self.transform(tile)\n",
    "                    \n",
    "                tiles.append(tile)\n",
    "                \n",
    "        # Select a random permutation from the pre-computed permutations\n",
    "        perm_idx = random.randint(0, self.n_permutations - 1)\n",
    "        perm = self.permutations[perm_idx]\n",
    "\n",
    "        # Shuffle the tiles according to the permutation\n",
    "        shuffled_tiles = [tiles[p] for p in perm]\n",
    "\n",
    "        # Stack tiles into a tensor\n",
    "        tiles_tensor = torch.stack(shuffled_tiles, dim=0)  # Shape: [9, 3, 64, 64]\n",
    "\n",
    "        # Return the shuffled tiles and the permutation index which is the gold label we aim the model to predict\n",
    "        return tiles_tensor, perm_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf96c46-4627-435f-903f-27e7a4a8152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812c32c-da8c-46af-af6a-b14f1fdb6ec6",
   "metadata": {},
   "source": [
    "## Instance the torch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3e6a08-0cf7-4bab-b757-a333b4dcbba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_permutations,\n",
    "                 architecture = 'resnet', # 'resnet' or 'vit'\n",
    "                ):\n",
    "        \n",
    "        super(JigsawNet, self).__init__()\n",
    "\n",
    "        if architecture=='resnet':\n",
    "            # Backbone ResNet model TODO: replace by ResNet 50\n",
    "            # self.resnet = models.resnet18(pretrained=False) # I thnk this is deprecated\n",
    "            self.resnet = models.resnet18() \n",
    "            self.resnet.fc = nn.Identity()  #Remove the classification layer\n",
    "            \n",
    "        elif architecture=='vit':\n",
    "            pass ##TODO\n",
    "\n",
    "        # Fully connected layers << to dispose after the PTT\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 9, 4096), # each genertaes a 512-dimensional vector\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, n_permutations)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 9, 3, 64, 64]\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Combine batch and tile dimensions (siamese network -> feed the same weights all the patches at once)\n",
    "        x = x.view(batch_size * 9, 3, 64, 64)  \n",
    "        features = self.resnet(x)  # Shape: [batch_size * 9, 512]\n",
    "\n",
    "        # Concatenate the patches before the linear layers that learns the differences\n",
    "        features = features.view(batch_size, 9 * 512)  # Shape: [batch_size, 9 * 512]\n",
    "\n",
    "        #\n",
    "        out = self.fc(features)  # Shape: [batch_size, n_permutations]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db629540-6598-423a-9d30-fee32e1774a8",
   "metadata": {},
   "source": [
    "## Training\n",
    "Hyperparameters should be adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d64757dc-f103-423a-a390-7d48d9eb6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JigsawNet(n_permutations=n_permutations)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9913e7fd-8f14-41b9-bf64-2aa8a915e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emilio.villa/miniconda3/envs/nlp24/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Create the datasets and dataloaders\n",
    "train_dataset = JigsawPuzzleDataset(tinyImageNet_dataset['train'], permutations, transform=transform)\n",
    "valid_dataset = JigsawPuzzleDataset(tinyImageNet_dataset['valid'], permutations, transform=transform)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c908c9da-0688-4539-9573-4ca3f130ce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset output: torch.Size([256, 9, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataset output: {}'.format(next(iter(train_loader))[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdef3072-51e9-43d9-8a2a-b4e2ddcf15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "num_epochs = 30\n",
    "log_each = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09a4366-d7c3-4d91-9a06-8cb873b09395",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'jigsaw_rn18_tinyimnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72def79d-4d44-47de-bd29-b4d110666c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▋                                                         | 100/391 [02:32<04:49,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Batch [100], Loss: 0.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████▍                                     | 200/391 [05:02<03:11,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Batch [200], Loss: 0.8180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████▍                          | 256/391 [06:30<03:25,  1.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (tiles, perm_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m      5\u001b[0m     tiles \u001b[38;5;241m=\u001b[39m tiles\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [batch_size, 9, 3, 64, 64]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     perm_idx \u001b[38;5;241m=\u001b[39m perm_idx\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [batch_size]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp24/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    for batch_idx, (tiles, perm_idx) in enumerate(tqdm(train_loader)):\n",
    "        tiles = tiles.to(device)  # Shape: [batch_size, 9, 3, 64, 64]\n",
    "        perm_idx = perm_idx.to(device)  # Shape: [batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tiles)  # Shape: [batch_size, n_permutations]\n",
    "        loss = criterion(outputs, perm_idx)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        if batch_idx % log_each == log_each - 1:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {avg_loss / 100:.4f}')\n",
    "            avg_loss = 0.0\n",
    "            \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for tiles, perm_idx in tqdm(valid_loader):\n",
    "            tiles = tiles.to(device)\n",
    "            perm_idx = perm_idx.to(device)\n",
    "\n",
    "            outputs = model(tiles)\n",
    "            loss = criterion(outputs, perm_idx)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += perm_idx.size(0)\n",
    "            correct += (predicted == perm_idx).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    if val_accuracy > best_accuracy:\n",
    "        print('Saving checkpoint')\n",
    "        torch.save(model.state_dict(), f'{model_name}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03bd8d2f-3ebb-40d7-b62a-c8626f2ab929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.96"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b32dd-6822-4370-92ba-75f8bd15a753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
