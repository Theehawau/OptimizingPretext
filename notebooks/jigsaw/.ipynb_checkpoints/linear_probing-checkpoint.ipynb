{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb0764-f13b-4afd-9bd7-5fdd58b63f8f",
   "metadata": {},
   "source": [
    "# JigSaw pretext task\n",
    "Following [the original implementation](https://arxiv.org/pdf/1603.09246) <br>\n",
    "Also useful to look at [the FAIR paper](https://arxiv.org/pdf/1905.01235) (page 12), for details on the implementation.<br>\n",
    "Adapted to use ResNet18 instead of CFN.\n",
    "TODO\n",
    "- Organize into separate .py modules for JigSaw utils\n",
    "- Create runner script that can use up to 4 GPUs for faster training.\n",
    "- Add ViT\n",
    "- Change training dataset to something w/ resolution of ~255x255 to avoid the need to upscate data\n",
    "- Add the evaluations -> basically take the (pretrained) resnet module and plug it into another module w/ a clean classification head \n",
    "    - linear probing\n",
    "    - full ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150c7425-5ca5-41b9-b507-1e58b5eef889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cdc376-2f79-4e82-85df-9400a180bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f13f6ce-5c49-4582-a48f-5cf9007a7518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x152750083750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility -> maybe use pytorch lightning for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b2f0d-4b60-42b4-ab97-310fa9992e09",
   "metadata": {},
   "source": [
    "## Load Tiny-ImageNet from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f139d43-ccdb-4e7e-b145-55e7a2aaf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinyImageNet_dataset = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "# We can also download it from here http://cs231n.stanford.edu/tiny-imagenet-200.zip but i think HFs its easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f3f690-4089-4f6b-876f-7efa5644439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinyImageNet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "400a2328-ddfd-4e6f-bc68-c9d50404668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCE TRAINING DATA TO K labels\n",
    "K = 10\n",
    "\n",
    "train_labels = list(set(tinyImageNet_dataset[\"train\"][\"label\"]))\n",
    "random.seed(42)  # For reproducibility\n",
    "selected_labels = random.sample(train_labels, K)\n",
    "filtered_train = tinyImageNet_dataset[\"train\"].filter(lambda example: example['label'] in selected_labels)\n",
    "filtered_valid = tinyImageNet_dataset[\"valid\"].filter(lambda example: example['label'] in selected_labels)\n",
    "filtered_dataset = {\n",
    "    \"train\": filtered_train,\n",
    "    \"valid\": filtered_valid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33f5905a-5bcc-41c3-a03b-a0284fb48b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " 'valid': Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 500\n",
       " })}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a22bc4-d843-4f0d-b7ea-58fdef5c5593",
   "metadata": {},
   "source": [
    "### Loading pretrained model and extracting features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba51f8cc-2d6b-4752-acac-b4747b18254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## aux -> model class\n",
    "class JigsawNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_permutations,\n",
    "                 architecture = 'resnet', # 'resnet' or 'vit'\n",
    "                ):\n",
    "        \n",
    "        super(JigsawNet, self).__init__()\n",
    "\n",
    "        if architecture=='resnet':\n",
    "            # Backbone ResNet model TODO: replace by ResNet 50\n",
    "            # self.resnet = models.resnet18(pretrained=False) # I thnk this is deprecated\n",
    "            self.resnet = models.resnet18() \n",
    "            self.resnet.fc = nn.Identity()  #Remove the classification layer\n",
    "            \n",
    "        elif architecture=='vit':\n",
    "            pass ##TODO\n",
    "\n",
    "        # Fully connected layers << to dispose after the PTT\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 9, 4096), # each genertaes a 512-dimensional vector\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, n_permutations)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 9, 3, 64, 64]\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Combine batch and tile dimensions (siamese network -> feed the same weights all the patches at once)\n",
    "        x = x.view(batch_size * 9, 3, 64, 64)  \n",
    "        features = self.resnet(x)  # Shape: [batch_size * 9, 512]\n",
    "\n",
    "        # Concatenate the patches before the linear layers that learns the differences\n",
    "        features = features.view(batch_size, 9 * 512)  # Shape: [batch_size, 9 * 512]\n",
    "\n",
    "        #\n",
    "        out = self.fc(features)  # Shape: [batch_size, n_permutations]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931c2148-443c-46bd-b069-7d2d8f8ee414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = JigsawNet(n_permutations=1).resnet\n",
    "pretrained_path = '/home/emilio.villa/nlp_local/cv_ptt/jigsaw_rn18_tinyimnt_resnet.pth'\n",
    "model.load_state_dict(torch.load(pretrained_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9ade4-2b3a-45d2-9412-b23b3c9a1706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "5c0e9438-93e5-4be9-931e-4a27c03f1645",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96d207ae-28c5-4d18-8bff-ceb65c773cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    '''\n",
    "    Given a pretrained ResNet model, extract features up to layer N [0,4]\n",
    "    \n",
    "    TODO -> update for resnet50\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 N,\n",
    "                 pretrained_model = None\n",
    "                ):\n",
    "        \n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        self.N = N\n",
    "\n",
    "        if pretrained_model is None:\n",
    "            ## instance resnet from scratch\n",
    "            print('resnet not provided, using random initialization')\n",
    "            pretrained_model = models.resnet18(weights=None) ##\n",
    "        else:\n",
    "            ## instance using previously trained resnet\n",
    "            print('resnet model provided, using it to initialize features')\n",
    "            # self.pretrained_model = pretrained_model\n",
    "\n",
    "        layers = [\n",
    "            pretrained_model.conv1,\n",
    "            pretrained_model.bn1,\n",
    "            pretrained_model.relu,\n",
    "            pretrained_model.maxpool\n",
    "        ]\n",
    "\n",
    "        if N >= 1:\n",
    "            layers.append(pretrained_model.layer1)\n",
    "        if N >= 2:\n",
    "            layers.append(pretrained_model.layer2)\n",
    "        if N >= 3:\n",
    "            layers.append(pretrained_model.layer3)\n",
    "        if N >= 4:\n",
    "            layers.append(pretrained_model.layer4)\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = pretrained_model.avgpool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecf911-a094-4250-8c31-1463fb8b90da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372fee5c-33a8-4766-a48b-c2bf3bedc73c",
   "metadata": {},
   "source": [
    "### Extracting train/test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42a07b96-3e07-44c5-b110-a56a47811de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the transforms\n",
    "classification_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define custom dataset class\n",
    "class ClassificationDataset(data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]['image'].convert('RGB')\n",
    "        label = self.dataset[idx]['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ecdbf2e-f62c-4b9e-9647-43e8d0ef6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    image_dataset,\n",
    "    feature_extraction_model,\n",
    "    batch_size = 512,\n",
    "    device = 'cuda'):\n",
    "    '''\n",
    "    Generates numpy array with features given a pretrained resnet model.\n",
    "    Parameters:\n",
    "    - image_dataset : Dataset object with the images to extract features from \n",
    "        NOTE: this is for the moment teh <ClassificationDataset> which generates images and labels, \n",
    "        should use other that only returns images\n",
    "    - feature_extraction_model : Module to extract features\n",
    "    - batch_size\n",
    "    Returns\n",
    "    - features : Numpy array with extracted features\n",
    "    '''\n",
    "    loader = data.DataLoader(\n",
    "            image_dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    "        )\n",
    "    feat_list = []\n",
    "    y_list = [] #lazy way to also extract labels\n",
    "    # counter = 0 ## delete\n",
    "    feature_extraction_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader): # update this if dataloader is replaced\n",
    "            images = images.to(device)\n",
    "            outputs = feature_extraction_model(images)\n",
    "            feat_list.append(outputs)\n",
    "            y_list.append(labels)\n",
    "            \n",
    "    return torch.cat(feat_list).cpu().numpy(), torch.cat(y_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "319bc2e8-c91e-4852-b4d5-08450eaf1f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet not provided, using random initialization\n"
     ]
    }
   ],
   "source": [
    "# feature_extractor = ResNetFeatureExtractor(N=1, pretrained_model = model).to(device)\n",
    "feature_extractor = ResNetFeatureExtractor(N=4, pretrained_model = None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76e6e0a2-2f8c-47e1-b693-35e80c202121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03cb4e2a-97aa-491a-8327-b493b719e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classification_dataset = ClassificationDataset(tinyImageNet_dataset['train'], transform=classification_transform)\n",
    "# val_classification_dataset = ClassificationDataset(tinyImageNet_dataset['valid'], transform=classification_transform)\n",
    "\n",
    "train_classification_dataset = ClassificationDataset(filtered_dataset['train'], transform=classification_transform)\n",
    "val_classification_dataset = ClassificationDataset(filtered_dataset['valid'], transform=classification_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "77177a72-7881-4b7a-81f8-d3f3de8aec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = extract_features(\n",
    "    image_dataset = train_classification_dataset,\n",
    "    feature_extraction_model = feature_extractor,\n",
    "    batch_size = 1024,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "X_test, y_test = extract_features(\n",
    "    image_dataset = val_classification_dataset,\n",
    "    feature_extraction_model = feature_extractor,\n",
    "    batch_size = 1024,\n",
    "    device = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e34b19cd-b307-48cb-b79d-d3e549a4d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 512) (5000,)\n",
      "(500, 512) (500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be650ebc-bbd9-4f40-97ae-e3b33d6618b5",
   "metadata": {},
   "source": [
    "### Fitting SVM classifier op top of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3155b4cc-f79b-4623-b807-3d90956dad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Grid Search Completed.\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 0.4480\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           6       0.46      0.52      0.49        50\n",
      "          26       0.30      0.46      0.37        50\n",
      "          28       0.44      0.54      0.48        50\n",
      "          35       0.42      0.38      0.40        50\n",
      "          57       0.37      0.40      0.38        50\n",
      "          62       0.59      0.44      0.51        50\n",
      "          70       0.33      0.30      0.32        50\n",
      "         163       0.55      0.46      0.50        50\n",
      "         188       0.58      0.56      0.57        50\n",
      "         189       0.60      0.42      0.49        50\n",
      "\n",
      "    accuracy                           0.45       500\n",
      "   macro avg       0.47      0.45      0.45       500\n",
      "weighted avg       0.47      0.45      0.45       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  5  3  5  1  2  1  1  2  4]\n",
      " [ 5 23  5  4  5  1  5  1  0  1]\n",
      " [ 3 10 27  1  1  0  4  1  2  1]\n",
      " [ 3  6  9 19  2  2  3  4  1  1]\n",
      " [ 3  6  3  3 20  4  7  4  0  0]\n",
      " [ 2  6  3  4  7 22  2  3  1  0]\n",
      " [ 4 11  2  2  5  3 15  4  1  3]\n",
      " [ 6  4  4  1  8  2  2 23  0  0]\n",
      " [ 3  2  5  3  3  0  2  0 28  4]\n",
      " [ 1  3  1  3  2  1  4  1 13 21]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Optional: Scale the features for better SVM performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],           # Regularization parameter\n",
    "    'kernel': ['linear'],#, 'rbf'],  # Kernel type\n",
    "    'gamma': ['scale']#, 'auto']    # Kernel coefficient for 'rbf'\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with a progress bar\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,                # 3-fold cross-validation\n",
    "    n_jobs=-1,           # Use all available CPU cores\n",
    "    verbose=3            # Verbose output to monitor progress\n",
    ")\n",
    "\n",
    "# Fit the model on the training data with a progress bar\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Grid Search Completed.\")\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1fc5c-9691-4d61-84ae-a1319cdaa425",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_classes,\n",
    "        architecture = 'resnet', #'resnet \n",
    "        pretrained_model = None,\n",
    "        ):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        # Use the pretrained ResNet model from the PTT task\n",
    "        \n",
    "        if architecture=='resnet':\n",
    "            # Backbone ResNet model TODO: replace by ResNet 50\n",
    "            self.features = models.resnet18() \n",
    "            # self.resnet.fc = nn.Identity()\n",
    "            self.features.fc = nn.Identity()  #Remove the classification layer ### IS this necessary??\n",
    "            \n",
    "        elif architecture=='vit':\n",
    "            pass ##TODO\n",
    "            \n",
    "        # Classification layer\n",
    "        self.linear_proj = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 3, H, W]\n",
    "        features = self.features(x)  # Shape: [batch_size, 512]\n",
    "        out = self.linear_proj(features)  # Shape: [batch_size, num_classes]\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
